# | Generative AI: Enhance your Data Analytics Career |

# DATA ANALYTICS AND GENERATIVE AI

This module introduces Generative AI for Data Analytics. You will explore several generative AI tools used in data analytics and gain insights into implementing them successfully. The module covers using generative AI for tasks like data generation and augmentation, data preparation, querying databases, and obtaining insights from Q&A models.

Learning Objectives:

    Define Generative AI.
    Provide examples of Generative AI applications.
    Demonstrate the use of generative AI for data generation, augmentation, and handling missing values.
    Apply generative AI techniques for merging data tables through join operations.
    Utilize AI assistants for data analysis and rule creation.
    Demonstrate quick insights extraction from massive data sets using generative AI.
    Apply generative AI tools to interpret and convert natural language queries into SQL commands.
    Explain the key aspects of question and answer (Q&A) in data analytics.
    List and discuss generative AI-driven frameworks used for Q&A in data analytics.
    Explore companies leveraging generative AI for data preparation.


## COURSE INTRODUCTION

Welcome to this course where you will learn
about using generative AI for data analytics.
Generative AI is artificial intelligence
that has revolutionized
data analysis by transforming
existing information into concise, fresh content.
Instead of coping with incomprehensible data,
you can streamline the information into
straightforward and insightful observations
in simple language quickly.
Generative AI can create synthetic data,
create insightful visuals from complex data,
fill in missing values in a data set,
generate code from prompts in plain language, and so on.
If you are aspiring to become a data analyst with
knowledge of this progressive technology,
this course is for you.
This is the third course in the generative AI for
data analytics program and caters to all learners seeking
for a career in data analytics with basic knowledge of
artificial intelligence and with
some experience in data analysis.
This three-module course welcomes
any aspiring data analyst
inclined to learn about generative AI.
This course does not require any prior degree.
However, having a basic knowledge of data analytics,
artificial intelligence, prompt engineering,
Python programming, and
generative AI would be beneficial.
In the first module,
you will learn about the different
generative AI tools available for
data analytics and the successful implementations
of generative AI and data analytics.
You will also learn about the use of
generative AI for data generation,
preparation and augmentation, database querying,
and Q&A model and insights.
In the next module, you will learn how to
draw insights from a dataset using
different generative AI tools and
use generative AI for data visualization.
You will also learn how to use generative AI to
create interactive dashboards and storytelling.
In addition, you will understand the considerations,
challenges, and ethical usage using generative AI.
In the final module, you will do
a guided practice project and
go through the key takeaways from this course.
You will also complete
the final assessment of this course.
There's a lot to cover here.
To get the most out of this course, view each video,
read through all the articles,
complete all hands-on activities,
and check your learning with each quiz.
If you need help, please reach out to
your peers or the course staff
on the course discussion forums.
We're thrilled to have you join
us on this learning journey.
Let's get started. Good luck. 


## COURSE SYLLABUS AND PREREQUISITES

- Abstract

Generative AI for Data Analytics demonstrates the integration of Generative Artificial Intelligence (Generative AI) in Data Analytics. This course demonstrates how to use generative AI tools/frameworks/platforms to increase the effectiveness of various processes involved in the data analytics life cycle.  

You will learn how to use and apply generative models for tasks such as data generation, data augmentation, data preparation and finding insights, querying databases, generating visualizations, and storytelling. You will also explore challenges and ethical considerations associated with using Generative AI in data analytics.

- Disclaimer:

In the course, you will be using free versions or trials of various Generative AI tools to learn the various concepts. Paid versions are not required to complete this course. If you decide to upgrade to a paid version, you will be responsible for any charges that you may incur. 

- Course prerequisites:  

An introductory knowledge of data analytics, generative AI, and prompt engineering would be beneficial.  You can check these courses to get a basic understanding of these topics:

    Generative AI: Introduction and Applications
    Generative AI: Prompt Engineering Basics

- Course Syllabus:

Module 1: Data Analytics and Generative AI

    Welcome

    Data Analytics and Generative AI  

    Generative AI for Data Preparation and Insights

    Module Summary & Assessment

Module 2: Use of Generative AI for Data Analytics

    Generative AI for Data Visualization and Storytelling

    Generative AI Considerations in Data Analytics 

    Module Summary & Assessment

Module 3: Final Project and Final Exam

    Final Project

    Final Exam

    Course Wrap-Up



# DATA ANALYSIS & GenAI

## Generative AI for Data Analytics 

Welcome to a new era of
data analytics where the fusion of
artificial intelligence and data exploration is
revolutionizing how you
understand and interpret information.
In this video, you will dive into
generative AI and its
transformative role in data analytics.
After watching this video,
you'll be able to define generative AI,
describe applications in generative AI.
Generative artificial intelligence, or generative AI is
a category of AI that
focuses on creating new synthetic data.
Unlike traditional AI models that predict or classify,
generative models generate entirely new data points,
opening a realm of possibilities for data analytics.
The applications of generative
AI and data analytics are vast.
Imagine being able to generate
synthetic data sets for testing and development,
enhancing data visualizations,
and filling in missing data points.
Generative AI is a game changer
in the field of data analysis.
Let's learn about some applications of generative AI.
Generative AI can create synthetic data sets,
solving the challenge of limited data availability.
It creates synthetic data sets
and augments existing ones,
providing analysts with diverse and enriched data
for robust analysis and model training.
These models can fill in missing data,
providing a more complete picture
for analysts and data scientists.
Transforming data into
different representations is another frontier.
Generative AI can convert texts
into images or vice versa,
giving analysts new perspectives and
creative ways to represent complex information.
Data preparation is crucial
in the data analytics journey.
Generative AI contributes by
automating and enhancing data cleaning,
normalization, transforming processes,
and streamlining the path from
raw data to actionable insights.
When it comes to querying databases,
generative AI brings efficiency and innovation.
It can assist in formulating complex queries,
optimizing database interactions,
and adapting to evolving data structures.
Imagine having an intelligent
assistant for your data queries.
Generative AI empowers Q&A models,
enabling users to interact with data naturally,
ask questions in plain language,
and receive meaningful insights in return.
For instance, Open AI GPT is a potent,
fine-tunable language model for tasks like Q&A.
In contrast, BERT,
a Google-developed pre-trained model,
excels in contextual understanding,
enhancing the capacity to comprehend and
respond to user queries in Q&A application.
Generative AI can enhance
the quality and aesthetics of data visualizations,
making them informative and visually striking.
Imagine interactive visualizations that
adapt to user input and exploration.
It contributes to data visualization by
generating visually appealing representations,
making complex information more accessible and engaging.
Generative AI combined with dynamic visualization tools,
creates an immersive and responsive
data exploration experience.
For example, Tableau AI,
the AI assistant of
IBM Cognos and Google's Looker AI, to name a few.
Generative AI simplifies and
accelerates dashboard creation,
offering dynamic layouts, insightful widgets,
and personalized user experiences
for more effective data communication.
Generative AI enhances storytelling in data analytics.
It can generate narrative elements,
highlight key insights,
and provide a cohesive structure
transforming raw data into compelling narratives.
The future holds endless possibilities on the cusp of
this exciting fusion between
generative AI and data analytics.
From automating exploratory data analysis
to creating captivating data driven narratives.
Generative AI is reshaping the data analytics landscape.
In this video, you learned
that generative AI is not just a tool,
it's a catalyst for innovation in data analytics.
Generative AI is shaping the future
where data is not just analyzed but created,
redefining what's possible in the world of information.
From data generation to
insightful visualizations and engaging storytelling,
generative AI reshapes how
you interact and derive meaning from data. 


## Generative AI Tools for Data Analytics 

Generative AI, a field of artificial intelligence that focuses on creating new data, is rapidly revolutionizing data analytics. By employing advanced machine learning algorithms, generative AI tools can analyze vast data sets and uncover hidden patterns, enabling businesses to make informed decisions, optimize processes, and gain a competitive edge.

Several generative AI tools empower data analysts to extract deeper insights from data. These tools encompass diverse capabilities, catering to specific data analytics needs.

- RapidMiner: A comprehensive platform for data science and machine learning, incorporating generative AI capabilities for predictive modeling and data augmentation.
- Tableau: The leading data visualization tool that has integrated generative AI features to automate data preparation and generate insights with natural language queries.
- IBM Cognos Analytics: Cognos Analytics offers AI-powered automation and insights, allowing users to describe data and test hypotheses. This transforms business teams into power users, allowing data analysts to focus on deeper insights. AI capabilities provide accurate, trusted business information, forecast future outcomes, and explain why they may happen.
- Google AI's Imagen: A text-to-image diffusion model that can generate realistic and creative images from text descriptions. It can create data for image classification, object detection, and image segmentation tasks.
- OpenAI's DALL-E 2: A text-to-image diffusion model similar to Imagen. It can also generate realistic and creative images from text descriptions. However, DALL-E 2 is still under development and unavailable to the public.
- Nvidia's StyleGAN2: A generative adversarial network (GAN) that can generate high-quality images of faces. It can create data for face recognition and facial expression analysis tasks.
- DeepMind's Gato: A general-purpose AI agent can perform various tasks, including data analytics. It can generate data for tasks such as text classification, sentiment analysis, and machine translation.
- Hugging Face's Transformers: A natural language processing (NLP) library that includes a variety of generative models, such as GPT-3 and BART. These models can generate text, translate languages, and write creative content.
- Salesforce Einstein GPT: A large language model (LLM) integrated into the Salesforce Einstein platform. It can generate data for various tasks, such as customer service, sales, and marketing.
- Google Cloud AutoML: A suite of machine learning products that includes a variety of generative models, such as AutoML Natural Language and AutoML Tabular. These models can generate data for various tasks, such as text classification, sentiment analysis, and image classification.
- IBM Watson Studio: A cloud-based data science platform that includes a variety of generative models, such as Watson Natural Language Understanding and Watson Visual Recognition. These models can generate data for various tasks, such as text classification, sentiment analysis, and image classification.
- Microsoft Azure Machine Learning: A cloud-based machine learning platform that includes a variety of generative models, such as Azure Cognitive Services Text Analytics and Azure Cognitive Services Computer Vision. These models can generate data for various tasks, such as text classification, sentiment analysis, and image classification.
- Amazon SageMaker: A cloud-based machine learning platform that includes a variety of generative models, such as Amazon Comprehend and Amazon Rekognition. These models can generate data for various tasks, such as text classification, sentiment analysis, and image classification.
- OpenAI's Code Interpreter: The ChatGPT Advanced Data Analysis, formerly known as Code Interpreter, is a plugin released in July 2023 that enables ChatGPT users to upload data or code and prompts ChatGPT to perform analysis and generate insights. Using the plugin, ChatGPT can create visualizations (charts, maps, and so on) and summarize the data.
- Lime: This tool explains the decisions made by machine learning models.
- SHAP: This tool explains the decisions made by machine learning models.
- Captum: This is a library of explainable AI tools for PyTorch.
- DataWrangler: This tool uses natural language processing (NLP) to clean and normalize data.
- OpenRefine: This tool transforms data by applying various operations, such as filtering, sorting, and grouping.
- Featuretools: This tool generates new features from existing data automatically.
- H2O Driverless AI: This tool uses machine learning to generate and select features automatically.
- TPOT: This tool uses genetic programming to generate and optimize machine learning pipelines automatically.
- Prophet: It forecasts time series data.
- LightGBM: It builds gradient-boosting trees for machine learning.
- XGBoost: It builds gradient-boosting trees for machine learning.
- StyleGAN: It generates realistic images of faces.
- CycleGAN: It translates images from one style to another.
- BigGAN: This generates high-resolution images.
- spaCy: This is a tool for natural language processing in Python.
- Stanford CoreNLP: This is a tool for natural language processing in Java.

NOTE: StyleGAN, CycleGAN, and BigGAN are all generative AI tools that can generate realistic images. These tools use various techniques, such as generative adversarial networks (GANs), to create new images similar to real-world images.

Other tools, such as DataWrangler and OpenRefine, are not directly based on generative AI but can be used to create training data for generative AI models. These tools can be used to clean and normalize data and transform data into a format suitable for training generative AI models.

Still, other tools, such as Prophet, LightGBM, and XGBoost, are not generative AI tools, but they can be used in conjunction with generative AI models to improve the performance of predictive modeling tasks. These tools can be used to build machine-learning models to make predictions based on historical data.

Integrating generative AI into data analytics is still in its early stages, but its potential is immense. As generative AI models evolve, they will become increasingly sophisticated in their ability to analyze data, uncover hidden patterns, and provide actionable insights. Data analysts who embrace generative AI will be well-positioned to extract maximum value from data, drive innovation, and transform their organizations.

Generative AI transforms the data analytics landscape, empowering businesses to make informed decisions, optimize processes, and gain a competitive edge. By harnessing the power of generative AI, data analysts can uncover hidden patterns, predict future trends, and personalize insights, driving innovation and shaping the future of business.


## Examples of Generative AI in Data Analytics 

Various companies across different industries are
utilizing generative AI to
enhance their data analytics efforts.
Let's see some examples of companies
using generative AI in data analytics.
After watching this video,
you'll be able to describe
some examples of generative AI.
Alteryx is an American computer software company
based in Irvine, California.
The Alteryx AiDIN is an innovative AI engine that
integrates the robust, user-friendly capabilities
of generative AI and
machine learning ML throughout
the established secure and enterprise-grade features
of the Alteryx Analytics Cloud platform.
Alteryx AiDIN is designed to enable individuals
to make intelligent decisions
across the entire enterprise.
PGA golfer Martin Trainer uses
Alteryx to generate training recommendations.
Alteryx can provide golfers with invaluable insights and
personalized recommendations
using innovative statistical metrics
like strokes gained and advanced predictive tools.
Netmeds is one of India's most
reliable and accessible pharmacies backed
by a founding family with a rich history of
providing quality medicine for over 100 years.
The onset of the pandemic led to
a substantial increase in website traffic,
with individuals seeking information on medicines,
prescriptions, and related queries at all hours.
Recognizing the need to address the surge effectively,
Netmeds collaborated with Haptik to develop
a chatbot capable of managing its core challenges.
The chatbot solution built by Haptik helped make
a significant and quantifiable
business impact for Netmeds while
allowing it to manage the sudden surge
in demand caused by the pandemic.
Specifically, it saved over 2,600 agent hours,
achieved an automation rate of 83.6%,
and improved first response times by 99%.
AI recommendations effectively use
data analytics to identify
patterns and trends in customer interactions,
providing valuable insights into
customer behavior and preferences.
This customer information enables Haptik to make
data-driven decisions
regarding personalized recommendations,
enhancing customer satisfaction,
and overall business performance.
DataRobot uses generative AI to augment
datasets by creating synthetic data points.
This data augmentation technique helps improve
machine learning models performance by providing
more diverse and comprehensive training data.
The DataRobot AI platform offers
unmatched capabilities in
experimentation and production,
providing manufacturers with the tools
to attain operational excellence,
minimize downtime, elevate product quality,
and augment customer satisfaction.
The unparalleled synergy of
generative and predictive AI lowers costs.
Prominent global manufacturers are proactively adopting
AI and its full potential to
maintain a competitive edge in the industry.
84.51 degrees harnesses the power of data robot to
empower its data scientists
relying on the platform to enhance the production,
deployment, and interpretation of data science models.
Palantir Artificial Intelligence Platform,
Palantir AIP is a software platform that
enables organizations to activate
and integrate large language models,
LLMs, and other AI capabilities
on their private networks,
while ensuring security, privacy, and compliance.
It provides a secure infrastructure for running LLMs,
managing data access, and auditing usage.
This infrastructure allows organizations
to leverage the power of AI without
compromising the sensitivity of
their data or exposing it to unauthorized access.
IBM uses generative AI to assist data analysts in
generating natural language descriptions
for data visualizations,
which allows for automated report generation,
making data insight more
accessible to a broader audience.
Google Analytics 4 uses generative AI to automate
data analysis and generate
more actionable business insights.
McDonald's and Hong Kong implemented
Google Analytics 4 for real-time ecommerce data.
Google Analytics 4
automatically suggests predictive audiences,
identifying high likelihood purchasers
in the next seven days.
Predictive audiences in Google Analytics 4,
anticipate future purchases with
conditions like the purchase probability metric.
McDonald's tested, ready to use
predictive audiences meeting
prediction modeling prerequisites.
Google Analytics rapid predictive
audience generation shorten months
of data analysis to weeks.
Facebook Insights is using
generative AI to provide businesses with
more comprehensive understanding of
their Facebook page engagement and advertising campaigns.
Facebook Business Suite uses
generative AI for data analytics in various ways.
Audience Insights.
Facebook Business Suite uses generative AI to analyze
data on Facebook and create detailed audience insights.
This information can be used
to target advertising campaigns
more effectively and personalize
content for different audience segments.
Ad performance optimization.
Generative AI analyzes add
performance data and identifies improvement areas.
This analysis can help businesses
optimize their ad spend
and achieve their marketing goals.
Creative content generation.
Generative AI can generate
creative content such as ad copy, images, and video.
This generation can help businesses save time
and create engaging content
that resonates with their audience.
Predictive analytics.
Generative AI predicts customer behavior and trends.
You can use this information to make
informed decisions about marketing campaigns,
product development, and customer services.
Vision Express. A retail eyecare chain
embraced Facebook business suites to enhance
its brand presence and streamline
customer interaction amidst its transition to e-commerce.
This shift yielded a month savings of
36 hours and a surge in direct message inquiries,
doubling the previous volume.
As generative AI technology continues to evolve,
you can expect to see
even more innovative and transformative applications
of this technology in business data analytics.
Generative AI can revolutionize how businesses collect,
analyze, and use data to make
informed decisions and drive business growth.
In this video, you learned
that Alteryx AiDIN is designed to
empower individuals in advanced intelligent decision
making across the entire enterprise.
The chatbot solution built by Haptik helped make
a significant and quantifiable
business impact for Netmeds,
while allowing it to manage
the sudden surge in demand caused by the pandemic.
The DataRobot AI platform offers
unmatched capabilities in experimentation and production.
Palantir Artificial Intelligence Platform, Palantir AIP,
is a software platform for running LLMs,
managing data access, and auditing usage.
Google Analytics 4 is using generative AI to automate
data analysis and generate
more actionable insights for businesses.
Facebook Insights uses generative AI to give businesses
a more comprehensive understanding of
their Facebook page engagement and advertising campaigns. 


## Case Study on Successful Implementations of Generative AI in Data Analytics

IBM watsonx is a powerful data analytics platform that helps businesses collect, analyze, and visualize data to gain insights and make informed decisions. It offers a comprehensive suite of tools and features for data scientists, business analysts, and data-driven decision-makers.

### Key Features of IBM watsonx for Data Analytics

- Data collection and integration

watsonx provides various tools for connecting diverse data sources, including databases, cloud storage, and real-time data streams. It seamlessly integrates data from different formats and structures, enabling a unified view of the organization's data landscape.

- Data preparation and preprocessing

watsonx offers data cleaning, transformation, and wrangling capabilities to prepare data for analysis. It automates repetitive tasks, identifies and handles missing values, and transforms data into a format suitable for analysis.

- Exploratory data analysis (EDA)

watsonx provides interactive data visualization tools to explore and understand patterns, trends, and anomalies within the data. It allows users to visually examine data distributions, correlations, and outliers, gaining insights into the underlying data patterns.

- Machine learning and predictive analytics

watsonx offers a range of machine-learning algorithms and tools for building predictive models. It supports supervised, unsupervised, and reinforcement learning techniques, enabling businesses to forecast future trends, identify customer behavior patterns, and optimize decision-making.

- Real-time data analytics

watsonx provides capabilities for real-time data ingestion, analysis, and visualization. It enables businesses to monitor events as they happen, identify potential issues, and make timely decisions based on real-time insights.

- Explainable AI (XAI)

watsonx incorporates XAI features to explain machine learning models' reasoning and decision-making processes. It helps users understand the factors contributing to model predictions, ensuring transparency and accountability in AI-driven decisions.

- Collaboration and knowledge sharing

watsonx supports collaborative data analysis workflows, enabling teams to share data, insights, and models. It facilitates knowledge sharing and fosters a data-driven culture within the organization.

- Deployment and integration

watsonx provides tools for deploying data analysis models and integrating them into business processes and applications. It enables businesses to leverage data insights to drive operational efficiency, improve customer experiences, and gain a competitive edge.

### Case Study: NatWest Group's Digital Mortgage Support Transformation

- Background

Owning a home is a cherished dream for many, and a bank-issued mortgage is crucial in realizing this dream. However, obtaining a mortgage has become increasingly complex with evolving regulations and processes. Banks, including NatWest Group, are challenged to provide accurate real-time policy information tailored to each customer's unique needs throughout the home-buying process.

- The challenge

To streamline the mortgage application process, NatWest collaborated with IBM® to develop a digital mortgage support tool. This tool aimed to enhance customer loyalty, reduce call duration, and provide real-time support to home buyers.

- The solution

IBM Consulting™ and NatWest co-created "Marge," an AI-powered, cloud-based platform using IBM Watson Assistant technology on IBM Cloud®. Marge is intentionally personified as a member of the NatWest team, equipped with her evolving personality. Integrated into NatWest's existing data structures, Marge continually receives updates through content additions and customer interactions.

### Implementation and impact

- Increased customer loyalty

Since deploying the digital mortgage support tool, NatWest has witnessed a remarkable 20% improvement in customers' Net Promoter Score (NPS), a key metric for customer loyalty.

- Time savings

Call durations have seen a significant 10% reduction attributed to the efficiency of the digital mortgage support tool.

- Seamless support

During customer calls, NatWest employees now have a single access point for digital mortgage support. Marge assists by quickly providing relevant information when employees input keywords into a console.

- Technological backbone

The platform leverages IBM Watson Assistant technology and is hosted on IBM Cloud. Marge, residing directly on the cloud, is intricately embedded within NatWest's data structures. This ensures she has real-time access to new data, contributing to her continuous learning and evolving capabilities.

- Future prospects

As Marge evolves, NatWest aims to empower its employees further during the ongoing digital transformation. The ultimate goal is to align with IBM's vision for the next-gen business model - becoming a Cognitive Enterprise.

- About NatWest Group

NatWest is a prominent banking and financial services company headquartered in the UK. Serving approximately 19 million people, families, and businesses in the UK and Ireland, NatWest is committed to innovation and customer-centric solutions. With a focus on becoming a Cognitive Enterprise, NatWest continues to shape the future of banking.

- Key metrics

20% improvement in Customer NPS
10% reduction in Call Duration
Note: All metrics are based on data collected since the implementation of the digital mortgage support tool.

Ref: https://www.ibm.com/case-studies/natwest-group-watson

Various organizations across various industries are using IBM watsonx for data analysis. Here are a few examples:

### Healthcare
- Mount Sinai Health System

watsonx analyzes patient data to identify patterns and trends that can improve patient care.

- Mayo Clinic

watsonx is being used to develop a new diagnostic tool for Parkinson's disease.
St. Jude Children's Research Hospital: watsonx analyzes genomic data to identify potential drug targets for cancer treatment.

### Financial Services

- Barclays Bank

watsonx analyzes financial data to identify fraud and other financial crimes.

- Citibank

watsonx analyzes customer data to improve customer service and marketing campaigns.

- HSBC

Watsonx is used to analyze risk data to make more informed lending decisions.

### Retail

- Walmart

watsonx is used to analyze sales data to optimize product placement and pricing.

- Target

watsonx is used to analyze customer data to personalize marketing campaigns and recommendations.

- Kroger

watsonx analyzes supply chain data to improve efficiency and reduce costs.

### Manufacturing

- Siemens

watsonx analyzes sensor data from manufacturing equipment to identify potential problems and prevent downtime.

- GE

watsonx is being used to analyze data from aircraft engines to predict maintenance needs.

- Ford Motor Company

watsonx is used to analyze vehicle data to improve fuel efficiency and safety.

### Energy and Utilities

- ExxonMobil

watsonx analyzes geological data to identify potential oil and gas reserves.

- National Grid

Watsonx is being used to analyze energy consumption data to identify areas where energy efficiency can be improved.

- Enel

watsonx analyzes weather data to predict energy demand and optimize power generation.

### Conclusion

These are just a few examples of the many organizations using IBM watsonx for data analysis. watsonx is a powerful tool that can be used to gain insights from data and make better decisions across a wide range of industries.



# GenAI FOR DATA PREPARATION & INSIGHTS

## Leveraging Generative AI in Data Analytic Process

The rise of generative artificial intelligence (AI) is driving a fundamental revolution in the data analytics field. Data analytics is the proess of gathering, cleaning, analyzing and mining data, interpreting results, and reporting the findings.

In the field of data analytics, generative artificial intelligence (AI) has become a disruptive force that is changing the way you gather, prepare, analyze, and interpret data. GitHub reports that developers may save time by using GitHub Copilot. Of those surveyed, 88% said they are more productive, and 96% said they are "faster with repetitive tasks."

- Leveraging Generative AI for Data Generation and Augmentation:

Generative AI has the enormous potential to transcend the constraints of the current data by creating new data points that closely resemble the features of existing data. This data augmentation technique, also known as data generation, has the power to tackle the problem of incomplete or unbalanced datasets, which is a frequent roadblock in the data analytics process. By generating new data, generative AI can:

1. Enhance the robustness and generalizability of machine learning models by providing a more diverse and representative training dataset.
2. Improve the accuracy of statistical analysis and predictive modeling by reducing the impact of data scarcity and bias.
3. Enable the exploration of hypothetical scenarios and simulations, providing valuable insights into potential outcomes and risks.

- Enhancing Data Preparation with Generative AI:

Data preparation, the initial phase of the data analytics process, involves cleaning, transforming, and organizing data to make it suitable for analysis. Generative AI can significantly streamline and enhance this process by automating tasks such as:

1. Data imputation: Filling in missing values in datasets to ensure data completeness and consistency.
2. Data anomaly detection: Identifying and correcting outliers or errors in data, improving data quality.
3. Data normalization: Standardizing data formats and scales to facilitate consistent analysis and comparison.

- Revolutionizing Data Querying with Generative AI:

Data querying, the process of retrieving specific information from a database, often involves complex SQL queries that can be time-consuming and error-prone. Generative AI can revolutionize data querying by:

1. Enabling natural language queries: Allowing users to ask questions about the data in a natural language format, simplifying the querying process for non-technical users.
2. Generating SQL queries automatically: Transforming natural language queries into optimized SQL queries, reducing the burden on data analysts.
3. Providing real-time query responses: Enabling interactive data exploration and analysis through real-time query execution.

- Uncovering Deeper Insights with Generative AI:

Generative AI can enhance the extraction of insights from data by:

1. Identifying hidden patterns and correlations: Detecting subtle relationships and associations within data that may not be apparent through traditional analysis techniques.
2. Generating hypotheses and explanations: Proposing potential explanations for observed patterns and trends, guiding further investigation.
3. Providing personalized insights: Tailoring insights to specific users or contexts, enhancing the relevance and actionable nature of data-driven insights.

- Creating Captivating Data Visualizations with Generative AI:

Data visualization plays a crucial role in communicating insights effectively. Generative AI can elevate data visualization by:

1. Generating creative and visually appealing visualizations: Creating intuitive and engaging visualizations that capture the essence of the data.
2. Adapting visualizations to different audiences: Tailoring visualizations to the specific needs and preferences of different user groups.
3. Generating interactive visualizations: Enabling users to explore and interact with data in a dynamic and immersive manner.

- Crafting Compelling Data-Driven Stories with Generative AI:

Effective storytelling is essential for conveying the significance of data-driven insights. Generative AI can assist in crafting compelling data-driven narratives by:

1. Generating narratives from data: Automatically summarizing key findings and insights into a coherent narrative.
2. Identifying storytelling elements: Highlighting relevant anecdotes, trends, and outliers that add depth and context to the story.
3. Tailoring stories to specific audiences: Adapting the narrative style and tone to resonate with the target audience.

- Embracing the Future of Data Analytics with Generative AI:

The integration of generative AI into data analytics workflows offers a plethora of benefits:

1. Enhanced data quality: Generative AI can improve data quality by identifying and correcting errors, imputing missing values, and detecting anomalies.
2. Improved model performance: Generative AI can enhance the performance of machine learning models by providing more robust and diverse training data, leading to more accurate predictions and insights.
3. Accelerated insight generation: Generative AI can automate and streamline data analysis tasks, enabling faster and more efficient extraction of insights from large datasets.
4. Uncovering hidden patterns: Generative AI can uncover hidden patterns and relationships in data that may not be apparent through traditional data analysis techniques.
5. Personalized insights: Generative AI can generate personalized insights tailored to specific users or contexts, enhancing the relevance and actionable nature of data-driven insights.

- Conclusion:

While generative AI holds immense promise, it is crucial to consider ethical considerations when adopting this technology. Data privacy, fairness, and transparency are paramount to ensure that generative AI is used responsibly and ethically:
Generative AI models should be trained and deployed on data that is handled with utmost care and respect for privacy. In a recent Salesforce survey, over 70% of IT directors expressed concern that "generative AI will introduce new security risks to our data."

- Additional Readings:

Recommended readings for more insights on generative AI for data analytics and the ethical considerations:
1. https://www.forbes.com/sites/garydrenik/2023/11/17/ai-assistants-everywhere-why-ethical-and-responsible-ai-is-our-most-important-investment/?sh=193eae097a7b
2. https://www.accenture.com/sk-en/insights/technology/generative-ai


## Generative AI for Data Generation and Augmentation

Welcome to this video on generative AI as
a useful tool for data generation and augmentation.
After watching this video,
you'll be able to explain how
generative AI is a useful tool
for data generation and augmentation.
Generate synthetic data using a generative AI-based tool,
and augment data using a generative AI-based tool.
Data augmentation is a powerful technique for
improving the performance of machine learning models,
especially when the training data sets of
the models are small or unbalanced.
It is the process of artificially increasing the size of
a training data set by creating
modified data from the existing one.
Since data can be categorized into three categories,
structured data, unstructured data,
and semi-structured data,
there can be many ways to generate
these categories of data or augment it.
Let's dive into some of the tools available
for each of these categories and investigate
how easily generative AI can be leveraged
for data generation and augmentation.
Structured data, often saved in tabular formats,
serves as a foundation for many machine learning systems.
CTGAN, which is
a conditional generative adversarial network of
transformer architecture for text to
image and synthetic data vault or SDV,
are examples of generative AI techniques
which excel in augmenting structure data sets.
These tools generate synthetic data
that mimics the statistical traits and
correlations seen in the original
data to handle data imbalances,
missing values, and privacy problems,
this can be especially helpful.
Semi-structured data such as text and
code poses unique challenges for data augmentation.
Generative AI tools like GauGAN
and Imagen can effectively augment
semi-structured data sets by generating
realistic text descriptions and code snippets.
This can enhance the performance
of machine learning models in
natural language processing and code-generation tasks.
Unstructured data, including images and audio,
is often difficult to augment
due to its inherent complexity.
Generative AI tools like
StyleGAN2 and BigGAN have demonstrated
remarkable capabilities in augmenting
image data sets by generating
high resolution, realistic images.
In addition, generative AI can be used to
augment audio data sets by synthesizing new audio samples.
For instance, SoundGAN by NVIDIA.
Let's check out some generative AI tools
for data augmentation and generation.
We'll navigate to the universal data website at
generate.universaldata.io and we'll begin
with a prompt to create the data set.
We type the prompt patient data set
for the symptoms of diabetes.
As of now, we will skip specifying the fields.
Then we generate the data,
the prompt might take a while to process.
The data is generated and we can view the response.
We can copy and download the generated data.
If we choose download,
a CSV file will be generated and saved.
Generative AI tools may have
different ways of creating data sets.
Some may be efficient, while
others would need extra work.
Let's use another tool, ChatGPT,
available free of charge.
This time we will specify the features of
the data we want to be generated in the prompt,
so we type the prompt as follows: Create
a data set with attributes as
temperature in Fahrenheit, temperature category,
humidity and percentage, wind speed in miles per hour,
wind direction, visibility, wind chill,
precipitation, fog, rain, and snow
as categorical, type in yes or
no categories, month, year,
and specify the data has to be created for
100 observations in a CSV format.
Then we submit this prompt
and the sample data is generated.
We could modify the values and
attributes based on our specific needs.
We could also copy this code
and run it in a Jupyter Notebook.
Let's provide the same prompt to another GPT tool.
We'll open the Bard web page at
bard.google.com and start a new session.
We'll use the same prompt as before.
Then we submit the prompt and the data is generated.
Notice that this tool has generated the data and
also generated some other
draft versions for us to review.
We could also copy the data to use it further.
In a different tool, let's upload
a data set and add parameters
to generate data more effectively.
We'll open the mostly AI website at synthetic.mostly.ai.
On the Upload files tab,
we click the icon to upload files,
then select the Daily_Car Sales data set.
Then click "Proceed," and we
can select a training goal for this job.
Options are accuracy,
speed, and turbo.
Each of these puts a focus on
one goal at the cost of the other.
As we select each one,
we can see that the training size
and training epoch number will change.
When we click "Create Synthetic
dataset," the epoch will be run,
which can take quite some time.
The status will say pending and
then in progress while it's being generated.
If you click the status link, you can see the progress.
Now it's finished,
let's have a look at the augmented data set.
The data set has generated the same number of
samples as there were in the original data set.
We can download the data set
and use it for our model training.
Finally, let's use coding to generate data.
We'll open the collaboratory website at
colab.research.google.com.
We open a new Notebook and first
we need to install the CTGAN module.
We will also need to install the table evaluator.
For this demonstration, we will use one of
the provided sample data sets called
california_ housing_train.CSV.
If we open the Files menu in
the left pane and then expand the sample data,
we can choose from several sample data sets.
Using Pandas we'll import one of
these sample CSV files into the lab Notebook.
Next, we fit CTGAN on the data using this code,
we need to import CTGAN.
If our data has categorical features,
we must pass them as a list to the fit function.
Let's run this code. It will take
a while to run 200 epochs.
Now we'll save the generated samples.
We can evaluate the samples on
how close they are to the original data.
For that, we will need to import table evaluator.
Then we print the shapes of the original and sample data.
Then we'll make a comparison of
the fake data and the original data.
If we create evaluation visualizations,
they will show that the generated fake data
is fairly similar to the original real data.
In this video, you learned that
data augmentation is the process of artificially
increasing the size of a training data set
by creating modified data from the existing one.
CTGAN and SDV are examples of
generative AI techniques that
excel in augmenting structure data sets.
Generative AI tools like GauGAN and
Imagen can effectively augment semi structured data sets.
Generative AI tools like
StyleGAN2 and BigGAN augment image data sets
while SoundGAN synthesizes new audio samples. 


## Generative AI for Data Preparation

Welcome to Generative AI for Data Preparation.
After watching this video, you'll be able to replace missing values and
find outliers in data, merge multiple data tables by using a join,
filter data, use the AI assistant to analyze data and create an if-then rule.
Data preparation is a crucial step in the process of data analytics,
which involves cleaning, transforming, and
organizing RAW data to make it suitable for further analysis and modeling.
This step ensures that the data is accurate, reliable, and consistent.
In this video, we will walk you through two demonstrations of how generative AI
makes data preparation easier and quicker for data professionals.
In this first demo, we will use the ChatCSV generative AI tool,
which is a web-based tool that acts as a personal data analyst assistant,
enabling you to attach any CSV file to a chat session and ask questions.
Let's begin by initiating a chat, we need to attach our data set,
the data set we will use is Daily_Car_Sales.csv.
Once the data set is uploaded, the GPT model displays the description and
basic information.
The generative AI tool also provides additional information on the columns that
contain missing values.
Now we will try to handle this missing value by writing a simple prompt like
replace missing values of temperature F with the mean of temperature F.
The updated data is ready in no time, with missing values of
the temperature column replaced with the average values.
Let's check the outliers in the data set,
see how the GPT has produced the box plots for each of the columns.
Here we can see that several of the data columns have outliers represented by
the black dots.
Generative AI makes it easy to work with data preparation tasks.
Let's move on to another platform and explore data preparation steps.
This free community version of Tomat.AI allows you to explore and
analyze your data without limitations.
Let's upload the data set, first we open our CSV file and
we can either drag and drop it from its location or browse to upload it.
In the top right of the page, we click add to catalog.
We are now in explorer and
can see statistics in the right hand pane of each column in the data set.
Let's see the average temperature for each category of weather condition,
to do this, we group by weather condition,
then select the temperature F column for the value and choose average.
When we click outside the dialog box, we can see the updated table
displaying average values of all different weather conditions.
Now we will go further and convert the data to a flow.
Let's now try using a filter on the data columns.
First, we'll upload another data table called Dealer_ID_Names.csv.
Here's the data file. We will click create to save our changes.
Now we're going to merge these two tables so we choose join and
connect the two table icons to the join icon.
For the type of join, we will pick left join and
we select dealer ID for both keys and create the join.
We can also include filters in our data.
Let's filter the data where the weather condition is scattered clouds.
Now we can only see rows with scattered clouds visible in the data.
You may also sometimes get suggestions from the AI assistant
on the suggestions tab for things like missing values or
other suggestions on different tables in your data set.
But we can also ask the AI assistant specific questions,
for example, in the general chat here we're going to ask the GPT how to deal
with missing values in the temperature column.
One of the suggestions from the AI assistant is to fill the missing values
with a constant, for example the average.
Let's do this by using an if-then rule.
We'll replace the missing temperature values with an average column value.
We select if..then from the new menu and then write the function to do so.
We select the is missing condition for the temperature F column and
if this is true we want the average value of the temperature to be attributed.
Otherwise, we want the actual temperature value as it is in the row.
Now we will choose to overwrite the temperature column and
then create the rule.
So now we can see an if item connected to the join filter.
Lastly, we need to include the output of the flow to generate
a CSV of this processed data, we select local file and
specify where to create it and we'll call it prepared data.
Now the flow is ready for the job, so we click the run job icon and
wait till the CSV is prepared.
This can take quite some time,
but once it's finished we can see the CSV containing the prepared data.
In this video, you learned that you can replace missing values in data.
You can manage outliers in data, you can find average values for
each data category, you can apply filters, merge data tables, delete columns,
and you can generate a CSV file of processed data. 


## Generative AI for Querying Databases

Welcome to generative AI for querying databases.
After watching this video,
you'll be able to demonstrate how
you can quickly and easily extract insights
from massive datasets using generative AI,
use generative AI tools to understand
natural language queries, and convert
natural language queries to SQL commands.
Querying a database involves retrieving
or manipulating data stored in a database.
A database refers to an organized collection of data
and queries refer to the primary means
of interacting with this collection and
extracting information from the database.
Structured query language or SQL is
the most common and standardized query language
for interacting with relational databases.
SQL queries consist of commands
that specify the data to be retrieved,
the conditions to be applied, and
the sequence in which to display the data.
Generative AI has changed
the way we interact with databases.
By enabling users to query databases
in natural language, generative AI
makes it easier for people
to access and understand data.
This ability can profoundly impact
a wide range of industries
from finance to healthcare to education.
Next, experience how you can quickly
extract insights from massive datasets.
Traditionally, data professionals
would spend hours crafting SQL queries
to navigate through the intricate database structure.
This demo uses SQL through AI.
A generative AI model designed
to understand natural language queries
and convert them into SQL commands.
We've logged into the platform.
We'll set up our first database for this tool.
First, we upload the Boston housing
price dataset that we want to query,
give it a name, and save it.
Now we can begin querying our data.
Notice that you can ask for the query
to be generated for various database
management systems or for languages
like SQL and Mongo DB, and others.
In this case, the request will be for an SQL query.
We can select the dataset and type the first prompt,
what are the column names, and run it.
Within seconds, the query is generated,
and we can copy and use the query in an application.
Now we want to generate a query
to know the count of rows in the dataset.
Again, we select the new query,
select the dataset to query on,
and enter our query prompt.
The response tells us that to retrieve
the count of rows in a database,
we can use the following SQL query.
SELECT COUNT(*) FROM Boston_house_prices.
Now we want to determine how to query
the average age in the database.
The response tells us that we can use the query,
select average age from Boston_house_prices.
Next, we want to create a query to find
all rows where taxes between 210-250,
and the quick query is generated as
SELECT * FROM Boston_house_prices
where tax is more than or equal to 210
and tax is less than or equal to 250.
That's pretty impressive.
Next, we want to know how to replace
zero values in the ZN column
with a constant value of five.
The response generated is
update "Boston_house_prices",
set "ZN = 5 where ZN = 0".
Next up, we want to know how to store the table
in ascending order on the MEDV column.
The quick response tells us that the query is
select "From Boston_house_prices
order by MEDV ascending".
Let's try to get a query to insert new rows.
Well, this query response
might not be as expected.
Nevertheless, we would need
to replace the null values with
actual values we want for each field.
Next, we'll generate a condition-based query.
We want to find the rows where
RAD is five and the age is between 50-55.
Well, the response says that
the query for this should be,
select "From Boston_house_prices
where RAD = 5 and age between 50 and 55".
Lastly, we want to know how
to create a sub-table where
CHAS is one and RAD is four.
The response comes back
and tells us how to create the sub-table
using the SQL statement,
SQL select "From Boston_house_prices
where CHAS = 1 and RAD = 4".
Querying databases is
an essential part of working with data.
By understanding how to write SQL queries,
you can effectively retrieve and
manipulate data to gain valuable insights
and make informed decisions.
Generative AI is playing a vital role
in query generation through
a simple natural language processing interface,
which saves time and effort.
In this video, you learned that
you can query for specific data from
a given dataset such as column names,
count of rows, and average age.
You can find specific rows,
replace values in a column,
and sort a table in ascending order.
You can insert new rows,
generate a condition-based query,
and create a sub-table. 


## Generative AI for Q and A Model Insights 

Welcome to Generative AI for Q&A Model insights.
After watching this video, you'll be able to,
explain the key aspects of question and answer, Q&A, for data and data analytics.
List some of the generative AI-driven frameworks used for Q&A for data.
Discuss the features of these frameworks.
As asking questions and getting answers about certain data sets or
data analysis activities is called Q&A for data.
This involves utilizing machine learning and
natural language processing (NLP) algorithms to comprehend and interpret queries,
providing relevant and accurate responses based on the available data.
With Q&A, you can accomplish data exploration, extract insights, and get
a better comprehension of the underlying patterns and trends in the data.
With its user-friendly interface, even individuals with limited analysis
experience can effectively engage with and query data.
Data Q&A is instrumental in revealing valuable insights and
patterns within data sets.
By posing targeted questions,
users can better understand the data in terms of identifying trends, outliers, and
correlations, and subsequently make more informed decisions.
Some of the generative AI-driven frameworks that organizations use for Q&A for
data are Cognos Analytics, Power BI, Tableau Pulse, ThoughtSpot,
Analytics Chatbot, Dash Enterprise, and Crystal.
Let's explore these frameworks.
IBM's Cognos Analytics is a comprehensive business intelligence BI
platform incorporating AI capabilities that support Q&A for data.
The Q&A capability leverages AI assisted data discovery, automated pattern
detection, and natural language querying to simplify the dashboard creation.
It enables users to define data and test hypotheses using automation and
insights driven by AI.
The AI assistant for natural language processing delivers precise, reliable,
and comprehensive business data.
Data analysts may now concentrate on gaining deeper insights and
forecasting future results, thanks to this new generation of BI.
The Q&A feature in Microsoft Power BI allows users to interact with their data
using natural language queries.
This feature facilitates data exploration, where users can ask questions about
trends, patterns, and specific data points without the need to write complex queries.
Power BI uses intelligent algorithms and natural language processing to interpret
user queries and generate accurate and meaningful responses.
It has a user-friendly interface that promotes a more intuitive and
interactive experience for users engaging with their data.
The Q&A feature seamlessly integrates with power BI dashboards,
enabling users to incorporate natural language queries into their data
exploration and analysis workflows.
Tableau Pulse from Tableau AI reimagines the data experience from business users,
empowering every employee with intelligent, personalized, and
contextual insights.
It brings up automated analytics in plain language, anticipates user questions,
suggests new questions, transforming how people engage with their data, and
helps organizations become data-driven.
ThoughtSpot Sage integrates the capabilities of large language models,
LLMs, and natural language processing and generative AI,
along with the search technology.
Data analysts, irrespective of their technology proficiency, can discover data
insights generated by AI and comprehend them in straightforward language.
ThoughtSpot Sage provides a relevant, trusted, personalized, and
actionable insights from data.
It also recommends questions and
suggests synonyms to optimize your search experience.
Analytics Chatbot from Sisense is an embeddable analytics conversational
chat service that enables business users to explore data for
insights using natural language inquiries.
It can generate data visualizations, provide narrative explanations and
contexts, and offer sample insights all through a single chat interface.
Dash Enterprise is a data visualization and
analytics platform that offers smart insights,
a feature that uses AI to extract key highlights from complex data sets.
Dash enterprise can analyze data quickly and efficiently and
provide valuable insights.
With the smart insights feature,
users can easily detect anomalies by identifying unusual trends, patterns, and
outliers in their data, helping them confidently make data-driven decisions.
Crystal from iGenius establishes a link between business and
data teams through conversational AI.
It comprehends your queries and
provides responses directly from your data without needing training.
It explores trends by proposing additional questions and
potential opportunities that might be overlooked.
It can detect anomalies by creating personalized alerts for critical KPIs and
sending automatic notifications when new patterns are identified.
Crystal also collaborates on data stories by showcasing all metrics in a unified
location and sharing pertinent data.
In this video, you learned that, Q&A for data is about asking questions and
getting answers about certain data sets or data analysis activities.
Some of the generative AI-driven frameworks that organizations use for
Q&A for data include Cognos Analytics, Power BI, Tableau Pulse,
ThoughtSpot, Analytics Chatbot, Dash Enterprise, and Crystal.
IBM's Cognos Analytics is a comprehensive bi platform incorporating AI
capabilities that support Q&A for data.
The Q&A feature in Microsoft's Power BI allows users to interact with their data
using natural language queries.
Tableau Pulse empowering data analysts with intelligent, personalized, and
contextual insights.
ThoughtSpot Sage integrates the capabilities of LLMs and
natural language processing and generative AI, along with the search technology.
Analytics Chatbot is an embeddable analytics conversational chat service that
explores data for insights using natural language inquiries.
Dash Enterprise is a data visualization and
analytics platform that uses AI to track key insights from complex data sets.
Crystal from iGenius establishes a link between business and
data teams through conversational AI. 

## Successful Implementations of Generative AI for Data Preparation and Insights 

Welcome to this video on successfully implementing
generative AI for data preparation and insights.
After watching this video,
you'll be able to describe
the implementation of generative AI in different fields,
describe various use cases where companies are
leveraging generative AI for data preparation,
discuss the features of these implementations.
Generative AI for data preparation
is an evolving technology.
Tech giants like Google AI,
Microsoft Azure Machine Learning,
and others are developing it and
bringing out new features quickly.
These organizations use generative AI
to synthesize missing data,
augment existing data sets,
and improve model performance.
In healthcare generative AI is used to create
synthetic medical images and patient records,
to train AI models in
drug discovery and clinical research.
In finance generative AI is being used to
synthesize financial data for risk modeling,
and anomaly detection and fraud prevention.
In retail generative AI is being used to generate
synthetic product images and descriptions for
personalized marketing campaigns
and recommendation systems.
Let's learn about some use cases where companies
leverage generative AI for data preparation.
In August 2023,
Walmart introduced a generative AI-powered
My Assistant to boost the output of its
50,000 corporate workers located in the US.
With My Assistant, Walmart's US corporate workers
can securely synthesize,
summarize, and augment
personal data from Walmart's ecosystem,
providing a consumer-grade experience to its workers.
Another example is Open AI,
which has developed a generative model called
GPT 3 or generative pre-train transformer 3.
GPT 4 is the most sophisticated system from Open AI,
which generates safer and more insightful replies.
GPTs can be used for
various tasks including data preparation.
Open AI is augmenting generative models and
general data augmentation and
data quality improvement across various domains.
Typeform, founded in 2012,
has introduced formless,
an AI-powered platform that
resembles human conversations.
The platform built with Open AI's GPT 3.5 turbo model and
GPT 4 allows users to
provide basic instructions for data collection.
The user-side experience mimics a real conversation with
questions responding to previous answers,
and two-way follow-ups.
Formless uses open AI technology to create,
manage, and analyze forms.
Creators can train AI to respond to
questions and customize it to the brand's tone.
Conversations work in any language,
and formless automatically translates
text based on the browser settings.
AI-driven natural language analysis
transforms conversational responses into data,
allowing the responses to act on results
with the platform's data pilot feature.
Stanford University is employing generative AI and
scientific research to synthesize
missing data in data sets and generating new hypotheses.
The adoption of generative AI
is expected to grow significantly
in the coming years as the technology matures
and becomes more accessible.
Kurt Lenglotz, Professor of Radiology,
Biomedical Informatics Research, and
Biomedical Data Science in
their research title, RoentGen,
Vision Language Foundation Model
for Chest x-ray Generation,
has demonstrated the modification of diffusion models,
a foundational model, to
generate clinical images that are from text prompts.
Their findings show that these models'
synthetic training data
may be added to actual training data
to improve diagnostic precision.
This type of artificial data might
assist in resolving machine learning issues,
such as the diagnosis and treatment of
rare diseases for which there is a lack of training data.
Sigma enables rapid data prototyping in a unique manner.
You can examine each row of data,
fix any issues with its quality,
and create a profile of the data.
In addition, Sigma gives
business people access to data sets in
an understandable state to enhance
user comprehension write back to
your cloud data warehouse using input tables.
In addition, you can operationalize your data using
Sigma's instantly recognizable
spreadsheet-like user interface.
An example of Sigma's application is Workato.
A corporate automation and
integration platform that helps
companies link their apps
and simplify intricate processes.
Workato uses Sigma to bring
in their data source, add new columns,
construct those columns using
formulae from existing columns,
link data, run V,
LookUps, and compile
all the data into a single final set.
Another organization that uses
generative AI for data preparation is DataRobot.
They offer an automated machine learning platform using
generative AI algorithms to assist with data cleaning,
feature engineering, and transformation.
H20.AI leverages generative AI for data preparation.
Their platform H20 driverless AI,
utilizes generative adversarial networks
(GANs) to automate and
optimize the data preparation process.
It's worth mentioning that the field
of generative AI is rapidly
evolving and new companies and
technologies may emerge in the future.
In this video, you learned that
organizations use generative AI
to synthesize missing data,
augment existing data sets,
and improve model performance.
In healthcare generative AI
creates synthetic medical images and
patient records to train
AI models in drug discovery and clinical research.
In finance generative AI is being used to synthesize
financial data for risk modeling
and anomaly detection and fraud prevention.
In retail generative AI
generates synthetic product images and
descriptions for personalized marketing campaigns
and recommendation systems.
Use cases leveraging generative AI
for data preparation are Walmart,
OpenAI, Typeform, Stanford University,
Sigma, Workato, DataRobot, and H20.AI. 



# WRAP-UP MODULE 1

## SUMMARY DA & AI

At this point in the course, you know:

- Generative AI serves as a catalyst for innovation, shaping a future where data creation redefines possibilities in information.

- From data generation to insightful visualizations and engaging storytelling, Generative AI reshapes how you interact and derive meaning from data.

- Various AI-driven solutions like Alteryx AiDIN, Haptik’s chatbot, DataRobot AI Platform, Palantir AIP, Google Analytics 4, and Facebook Insights contribute significantly to advanced decision-making, business impact, experimentation, data management, automated analysis, and comprehensive understanding of page engagement and advertising campaigns.

- Data augmentation is the process of artificially increasing the size of a training data set by creating modified data from the existing one.

- Generative AI tools like CTGAN, SDV, GauGAN, Imagen, StyleGAN2, BigGAN, and SoundGAN augment various types of data sets effectively.

- Data manipulation includes replacing missing values, managing outliers, applying filters, merging tables, deleting columns, generating CSV files, querying specific data, finding rows, replacing values, sorting tables, inserting new rows, and creating sub-tables.

- Q&A for data is about asking questions and getting answers about certain data sets or data analysis activities.

- Some of the generative AI-driven frameworks that organizations use for Q&A for data include Cognos Analytics, Power BI, Tableau Pulse, ThoughtSpot, Analytics Chatbot, Dash Enterprise, and Crystal.

- IBM’s Cognos Analytics is a comprehensive BI platform incorporating AI capabilities that support Q&A for data.

- Crystal from iGenius connects business and data teams through conversational AI.


## CHEATSHEET

### Important Terms:

- Generative AI: Is a category of AI that focuses on creating new, synthetic data. Unlike traditional AI models that predict or classify, generative models generate entirely new data points, opening a realm of possibilities for data analytics.

- Data Augmentation: Is a powerful technique for improving the performance of machine learning models, especially when the training data sets of the models are small or imbalanced.

- Data Preparation: Is crucial in the data analytics journey. To prepare raw data for analysis, it must be cleaned, transformed, and arranged in a format that makes it easy for analytical tools to use.

- Database Querying: Is the process of working with a database to extract relevant details for analysis. It includes interacting with a database and retrieving data that satisfies certain criteria using query languages, most often SQL (Structured Query Language).

- Data Q&A: Asking questions and getting answers about certain data sets or data analysis activities is called Q&A for data. With Q&A, you can accomplish data exploration, extract insights, and get a better comprehension of the underlying patterns and trends in the data.


### Generative AI Platforms/Tools Used in this Module:

- Data Augmentation and Generation

      DataRobot
      Colab
      ChatGPT
      Bard
      MOSTLY.AI
      universaldata

- Data Preparation

      ChatCSV
      Tomat.AI

- Data Querying

      SQLthroughAI
      dbsensei

- Data Insights through Q&A

      Akkio

### Some Generic Prompts:

- Create dataset in a particular domain 

  " Create <…..> dataset for <…..> "

  _Create patient data set for the symptoms of diabetes_

- Create dataset with specific attributes and format 
  " Create a dataset with attributes as <…..> in a <…..> format "
  _Create a dataset with attributes as temperature in Fahrenheit, Temperature Category, Humidity in percentage, Rain and Snow as categorical type in yes or no categories, Month, Year in a CSV format_

- Get the insights through Q&A: Finding hiehest value within the data attribute
  " Identify the <…..> with the highest <…..> "
  _Identify the products with the highest sales_
  _What are the top-selling products?_

- Get the insights through Q&A: See patterns of a data attribute over a period of time
  " How has <…..> changed over time? "
  _How has the quantity ordered changed over time?_

- Identify missing data
  " Write a <…> code to Identify <…..> missing values. "
  " Identify the attributes with missing data "
  _Write a python code to Identify the columns with missing values (ChatGPT)_
  _Identify the attributes with missing data (ChatCSV)_

- Handling missing values
  " Write a <…> code to replace missing values with <…..> in the dataset "
  " Replace the missing values <…> in the <…> and save the updated dataset "
  _Write a python code to replace missing values with mean values in the dataset (ChatGPT)_
  _Replace the missing values with the mean value in the Screen_size_cm column and save the updated dataset (ChatCSV)_

- Join two tables
  " Write a SQL query to join <…..> with <…..> on the <…..> as a primary key "
  " join <…..> with <…..> on <…..> as primary key "
  _Write an SQL query to join customer table with the product sales tables on product ID as primary key (ChatGPT)_
  _Join customer table with the product sales table on product ID as primary key (dbsensei)_

- Create database
  " Write a <…..> query to Create a database on <…..> "
  " create a <….> and insert values in these tables "
  _Create a database on <…..>, create tables, insert values 	Write a SQL query to Create a database on sales, create a customer table, a sales table, a product table and insert values in these tables (ChatGPT)_
_Create a database on customers and sales, create tables, insert values (dbsensei)_
